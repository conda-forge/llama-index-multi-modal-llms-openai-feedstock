{% set name = "llama-index-multi-modal-llms-openai" %}
{% set version = "0.5.3" %}
{% set python_min = "3.10" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  - url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/llama_index_multi_modal_llms_openai-{{ version }}.tar.gz
    sha256: b755a8b47d8d2f34b5a3d249af81d9bfb69d3d2cf9ab539d3a42f7bfa3e2391a
  # https://github.com/run-llama/llama_index/issues/10806
  - url: https://raw.githubusercontent.com/run-llama/llama_index/main/LICENSE
    sha256: 24f40b5190fdacabc24ddbb5f76364d15e4f030925220ea300d8a2dd4993c8cb

build:
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 0

requirements:
  host:
    - python {{ python_min }}
    - hatchling
    - pip
  run:
    - python >={{ python_min }},<4.0
    - llama-index-core >=0.12.47,<0.13
    - llama-index-llms-openai >=0.4.0,<0.5

test:
  imports:
    - llama_index.multi_modal_llms.openai
  commands:
    - pip check
  requires:
    - pip
    - python {{ python_min }}

about:
  home: https://llamaindex.ai
  dev_url: https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/multi_modal_llms/llama-index-multi-modal-llms-openai
  summary: llama-index multi-modal-llms openai integration
  license: MIT
  license_file: LICENSE

extra:
  recipe-maintainers:
    - jan-janssen
    - pavelzw
